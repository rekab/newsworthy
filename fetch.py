import bs4
import errno
import functools
import json
import demjson
import multiprocessing
import openai
import os
import os
import pprint
import random
import subprocess
import time
from http.server import BaseHTTPRequestHandler, HTTPServer


FIFO_PATH = "/tmp/my_fifo"

api_key = os.environ.get('API_KEY')
client = openai.OpenAI(api_key=api_key)

MAX_TOKENS = 3000

PROMPT_BASE = """I'm going to write a list of news headlines, and you need to score it according to the following criteria:

POLITICAL: Scale 0.0 to 1.0: Major political developments, such as a world leader's death, significant political upheaval, or high-profile trials of political figures.
GLOBAL: Scale 0.0 to 1.0: Significant global events, like breakthroughs in international agreements, major acts of terrorism, or significant natural disasters affecting large populations.
SCIENCE AND TECHNOLOGY: Scale 0.0 to 1.0: Groundbreaking scientific discoveries or technological advancements with far-reaching implications.
ECONOMY: Scale 0.0 to 1.0: Major economic shifts, like stock market crashes, significant mergers, or global economic policy changes.
OVERALL: Scale 0.0 to 1.0

Reply as a JSON dictionary, keyed by category with array values, consisting of a floating point score AND A SHORT STRING SUMMARING THE HEADLINES with an EXPLANATION WHY you chose that value. ONLY reply using JSON. DO NOT include anything other than JSON.

The headlines are:

"""


def read_new_news():
    print('reading NEW news')
    result = subprocess.run(
            ["curl", "https://news.google.com/home?hl=en-US&gl=US&ceid=US:en"],
            capture_output=True, text=True, check=True)
    return result.stdout


def read_old_news():
    print('reading old news')
    with open('curl-news-snapshot.2024-01-07.html', 'r') as f:
        return f.read()


def extract_headlines(html_content):
    soup = bs4.BeautifulSoup(html_content, 'html.parser')

    articles = []
    for link in soup.find_all('a'):
        href = link.get('href')
        if href is not None and href.startswith('./articles/') and link.text != '':
            articles.append(link.text)

    return articles


def request_chatgpt(prompt, max_tokens=200):
    """
    Sends a request to ChatGPT API using the openai package.

    :param prompt: The prompt to send to ChatGPT.
    :param max_tokens: The maximum number of tokens to generate.
    :return: The text generated by ChatGPT.
    """

    print('requesting gpt: ' + prompt)
    response = client.completions.create(
        model="gpt-3.5-turbo-instruct",
        prompt=prompt,
        max_tokens=max_tokens,
        temperature=0.7)

    return response.choices[0].text.strip()


def create_fifo():
    """ Creates a FIFO if it doesn't already exist """
    try:
        os.mkfifo(FIFO_PATH)
    except OSError as oe:
        if oe.errno != errno.EEXIST:
            raise


def is_file_old(fname, max_age=300):
    return time.time() - os.stat("news.json").st_mtime > max_age


def get_headlines_json():
    # Check if the file is older than 5 minutes
    if is_file_old("news.json"):
        print('file is old')
        # Perform a non-blocking write to the FIFO
        try:
            fifo_fd = os.open(FIFO_PATH, os.O_WRONLY | os.O_NONBLOCK)
            os.write(fifo_fd, b'1')
            os.close(fifo_fd)
        except OSError as oe:
            if oe.errno != errno.EAGAIN:
                raise

    # Read and return the contents of the file
    with open("news.json", 'r') as file:
        json_str = file.read()
        return demjson.decode(json_str)


class SimpleHTTPRequestHandler(BaseHTTPRequestHandler):

    def do_GET(self):
        if self.path == '/':
            self.send_response(200)
            self.send_header('Content-type', 'text/html')
            self.end_headers()
            with open('index.html', 'rb') as file:
                self.wfile.write(file.read())
        elif self.path == '/style.css':
            self.send_response(200)
            self.send_header('Content-type', 'text/css')
            self.end_headers()
            with open('style.css', 'rb') as file:
                self.wfile.write(file.read())
        elif self.path == '/script.js':
            self.send_response(200)
            self.send_header('Content-type', 'application/javascript')
            self.end_headers()
            with open('script.js', 'rb') as file:
                self.wfile.write(file.read())
        elif self.path == '/news.json':
            self.send_response(200)
            self.send_header('Content-type', 'application/json')
            self.end_headers()
            headlines = get_headlines_json()
            self.wfile.write(json.dumps(headlines).encode())
        else:
            self.send_response(404)
            self.end_headers()
            self.wfile.write(b'404 Not Found')


def run_server(server_class=HTTPServer, handler_class=SimpleHTTPRequestHandler):
    server_address = ('', 8000)
    httpd = server_class(server_address, handler_class)
    print("Server started at http://localhost:8000")
    httpd.serve_forever()


def headline_refresher():
    """ Consumer process that reads from the FIFO """
    while True:
        with open(FIFO_PATH, 'r') as fifo:
            print("Consumer: waiting for data")
            for line in fifo:
                print("Consumer: received data:", line.strip())

            if not is_file_old("news.json"):
                print('file is not old')
                continue

            with open("new.news.json", "w") as h_json:
                headlines = '\n'.join(extract_headlines(read_new_news()))
                print(headlines)
                prompt = PROMPT_BASE + headlines
                gpt_json = request_chatgpt(prompt, MAX_TOKENS)
                h_json.write(gpt_json)
                pprint.pprint(gpt_json)

            # rename for atomic swap
            os.rename("new.news.json", "news.json")


def main():
    create_fifo()

    # Create server and headline_refresher processes
    p = multiprocessing.Process(target=run_server)
    c = multiprocessing.Process(target=headline_refresher)

    # Start the processes
    p.start()
    c.start()
    print(f'Started. server pid: {p.pid} refresher pid: {c.pid}')

    # Wait for the processes to finish (they won't in this case, as they loop forever)
    p.join()
    c.join()


if __name__=='__main__':
    main()
